---
title: "TAPEX: Table Pre-training via Learning a Neural SQL Executor"
collection: publications
permalink: /publication/2022-01-21-tapex
excerpt: '**Qian Liu**, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou<br>In *International Conference on Learning Representations 2022* (**ICLR-2022**)'
date: 2022-01-21
venue:
---

\[[PAPER](https://arxiv.org/pdf/2107.07653.pdf)\] \[[CODE](https://github.com/microsoft/Table-Pretraining)\] \[[PROJECT PAGE](https://table-pretraining.github.io/)\]


![Demo](/images/tapex-demo.png)

Recent progress in language model pre-training has achieved a great success via leveraging large-scale unstructured textual data. However, it is still a challenge to apply pre-training on structured tabular data due to the absence of large-scale high-quality tabular data. In this paper, we propose TAPEX to show that table pre-training can be achieved by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries and their execution outputs. TAPEX addresses the data scarcity challenge via guiding the language model to mimic a SQL executor on the diverse, large-scale and high-quality synthetic corpus. We evaluate TAPEX on four benchmark datasets. Experimental results demonstrate that TAPEX outperforms previous table pre-training approaches by a large margin and achieves new state-of-the-art results on all of them.

This includes improvements on the weakly-supervised WikiSQL denotation accuracy to **89.5% (+2.3%)**, the WikiTableQuestions denotation accuracy to **57.5% (+4.8%)**, the SQA denotation accuracy to **74.5% (+3.5%)**, and the TabFact accuracy to **84.2% (+3.2%)**. To our knowledge, this is the first work to exploit table pre-training via synthetic executable programs and to achieve new state-of-the-art results on various downstream tasks.

Cite
===

```latex
@inproceedings{
  liu2022tapex,
  title={TAPEX: Table Pre-training via Learning a Neural SQL Executor},
  author={Qian Liu and Bei Chen and Jiaqi Guo and Morteza Ziyadi and Zeqi Lin and Weizhu Chen and Jian-Guang Lou},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=O50443AsCP}
}
```